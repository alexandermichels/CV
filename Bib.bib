@inproceedings{kang:SIGSPATIAL19,
    author = {J.-Y. Kang and J. Aldstadt and \textbf{A. C. Michels} and R. Vandewalle and S. Wang},
    title = {CyberGIS-{J}upyter for {S}patially {E}xplicit {A}gent-based {M}odeling: {A} {C}ase {S}tudy on {I}nfluenza {T}ransmission},
    booktitle = {GeoSim '19: Proceedings of the 2Nd ACM SIGSPATIAL International Workshop on GeoSpatial Simulation},
    editor = {Kavak, Hamdi and Kim, Joon-Seok and Wise, Sarah},
    year = {2019},
    isbn = {978-1-4503-6956-5},
    location = {Chicago, Illinois},
    publisher = {ACM},
    address = {New York, NY, USA},
    pages = {32--35}

@thesis{BSThesis,
    author  = {\textbf{A. C. Michels}},
    title   = {{C}apturing the {P}redictive {P}ower of {C}ortical {L}earning {A}lgorithms},
    school  = {Westminster College},
    year    = 2019,
    type    = {Bachelor's thesis},
    address = {New Wilmington, PA, U.S.},
    note    = {Bachelor's thesis},
    month   = {May}
}

@conference{JMM2019,
    author  = {H. Ahuja and \textbf{A. C. Michels}},
    title   = {Computational {F}act-{C}hecking through {R}elational {S}imilarity based {P}ath {M}ining},
    month   = {Jan},
    year    = 2019,
    note    = {AMS Contributed Paper Session at the 2019 Joint Mathematics Meeting},
    URL     = {https://jointmathematicsmeetings.org/meetings/national/jmm2019/2217_progfull.html?fbclid=IwAR0AccnUi_yuX4UdnTVF-cCFVJ5lNYAdIvzw7TPS81eGXk1pn5PvQjaGyTo#2217:AMSCP33}
}

@techreport{IPAMReport,
    author  = {H. Ahuja and \textbf{A. C. Michels} and L. Shi},
    title   = {Information {E}xtraction and {A}ggregation from {U}nstructured {W}eb {D}ata for {B}usiness {P}rofiling},
    institution = {Institute for Pure and Applied Mathematics and Praedicat, Inc.},
    address = {Los Angeles, California},
    abstract  = {Analysts at Praedicat, Inc., need to manually profile companies for modeling actuarial risks. With a plethora of companies and business activities, manual search is a tedious process. Further, the analysis is generally performed on unstructured, non-uniform, and sporadic websites which makes it difficult to algorithmically search for the information needed and complex to determine the semantic meaning of the documents even when they are found. Our work attempts to tackle these problems by building an information extraction, classification, and aggregation system which procures information and compares the statements found in the documents to a credible knowledge base. Based on computational fact-checking, we are hoping this approach will produce a better information extraction and aggregation system.},
    month   = {Aug},
    year    = {2018},
    pages   = {88}
}
